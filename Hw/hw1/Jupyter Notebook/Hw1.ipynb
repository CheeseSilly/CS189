{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "\traise Exception(\"Python 3 not detected.\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from scipy import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Data Partitioning , Evaluation Metrics and other necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the normalization\n",
    "def dataNormalization(training_data,test_data):\n",
    "    training_data=training_data.reshape(len(training_data),-1)\n",
    "    test_data=test_data.reshape(len(test_data),-1)\n",
    "    data=np.append(training_data,test_data,axis=0)\n",
    "    normalizedData = (data-np.min(data))/(np.max(data)-np.min(data))\n",
    "    index=len(training_data)\n",
    "    return normalizedData[0:index,:],normalizedData[index::,:]\n",
    "\n",
    "# do the data partitioning\n",
    "def dataPartitioning(data,labels,data_name):\n",
    "    labels=labels.reshape(len(labels),1)\n",
    "    dataset=np.concatenate([data,labels],axis=1)\n",
    "    np.random.seed()\n",
    "    np.random.shuffle(dataset)\n",
    "    if data_name==\"mnist\":\n",
    "        index=10000\n",
    "    elif data_name==\"spam\":\n",
    "        index=int(0.2*len(dataset))\n",
    "    validation_data=dataset[0:index]\n",
    "    training_data=dataset[index:-1]\n",
    "    return validation_data,training_data\n",
    "\n",
    "# do the Evaluation metric\n",
    "def evaluationMetric(true_labels,predict_labels):\n",
    "    sum=0\n",
    "    score=0\n",
    "    for true_label in true_labels:\n",
    "        for predict_label in predict_labels:\n",
    "            if(true_label==predict_label):\n",
    "                sum+=1\n",
    "    score=(sum)/len(true_labels)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Support Vector Machines: Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'training_lables is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_data\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_labels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m training_data,test_data\u001b[38;5;241m=\u001b[39mdataNormalization(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_data\u001b[39m\u001b[38;5;124m\"\u001b[39m],data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_data\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m val_dataset,training_dataset\u001b[38;5;241m=\u001b[39mdataPartitioning(training_data,\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_lables\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,data_name)\n\u001b[0;32m      6\u001b[0m train_x\u001b[38;5;241m=\u001b[39mtraining_dataset[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      7\u001b[0m train_y\u001b[38;5;241m=\u001b[39mtraining_dataset[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\CS189\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:265\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a file in the archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'training_lables is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "for data_name in [\"mnist\",\"spam\"]:\n",
    "    data = np.load(f\"../data/{data_name}-data.npz\")\n",
    "    training_data,test_data=dataNormalization(data[\"training_data\"],data[\"test_data\"])\n",
    "    val_dataset,training_dataset=dataPartitioning(training_data,data[\"training_lables\"],data_name)\n",
    "    train_x=training_dataset[:,:-1]\n",
    "    train_y=training_dataset[:,-1]\n",
    "    val_x=training_dataset[:,:-1]\n",
    "    val_y=training_dataset[:,-1]\n",
    "    if data_name==\"mnist\":\n",
    "        training_example=[100, 200, 500, 1,000, 2,000, 5,000, 10,000]\n",
    "    if data_name==\"spam\":\n",
    "        training_example=[100, 200, 500, 1,000, 2,000, len(train_y)]\n",
    "    model=svm.LinearSVC\n",
    "    train_score_list=[]\n",
    "    val_score_list=[]\n",
    "    for exa in training_example:\n",
    "        model.fit(train_x[:exa,:],train_y[0:exa])\n",
    "        train_score=evaluationMetric(train_y,model.predict(train_x))\n",
    "        val_score=evaluationMetric(val_y,model.predict(val_x))\n",
    "        train_score_list.append(train_score)\n",
    "        val_score_list.append(val_score)\n",
    "    plt.figure()\n",
    "    plt.title(\"Train&Validation for{}\".format(data_name))\n",
    "    plt.plot(training_example,train_score_list,'s',label=\"Training Score\")\n",
    "    plt.plot(training_example,val_score_list,'b',label=\"Validation Score\")\n",
    "    plt.legend()\n",
    "    plt.savefig(data_name+\".png\")\n",
    "    plt.show()\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
